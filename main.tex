\documentclass{article}

\usepackage[russian]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{Company Bankruptcy Prediction}
\author{Тардова Александра, Панов Максим}

\begin{document}
\maketitle

\begin{abstract}
Мы анализировали данные о банкротстве компаний с ресурса kaggle: \href{https://www.kaggle.com/datasets/fedesoriano/company-bankruptcy-prediction/}{доступен по ссылке}
\end{abstract}

\section{Использованные библиотеки}
Работа с данными:
\begin{itemize}
\item pandas 
\item numpy
\end{itemize}
Графики:
\begin{itemize}
\item plotly
\item seaborn
\item matplotlib.pyplot
\end{itemize}
Построение моделей машинного обучения и метрики качества:
\begin{itemize}
\item sklearn
\end{itemize}


\section{Работа с данными }

\subsection{Выбор данных}

В выданном датасете оказалось 96 колонок данных. Если использовать для обучения все, то можно получить эффект переобучения, ведь некоторые могут быть нерелевантны с точки зрения предсказания банкротства. Так, для построения модели логистической регрессии были использованы отношение денежнего потока к обязательствам, процентов долга к активам, текущих обязательств к активам и некоторые другие.

\subsection{Использованные модели и доказательство ее релевантности}

Мы считаем, что можно предсказывать банкротство конкретной компании по схожим с ней по характеристикам компаниям, поэтому мы решили использовать метод k-ближайших соседей, где схожесть вычисляется как расстояние между объектами на основе характеристик. Второй метод, которых мы использовали - это логистическая регрессия. Мы сочли этот метод подходящим, так как он отлично работает в задачах классификации, к которым относится и наша. То есть, наша вторая модель оценивает, является ли компания банкротом по нескольким заданным параметрам, исходя из данных, на которых она обучалась.



\subsection{Описание графиков}

Как было отмечено выше, датасет содержит слишком много параметров, поэтому мы использовали метод feature\_importances\_ из библиотеки sklearn. Далее взяли 10 самых важных и обучили модель на них. Они представлены на графике из plotly, с возможностью слайдинга по ОХ.

Для разнообразия, второй график было решено делать для оценки эффективности работы второй модели. Мы использовали метод ROC кривой (оценка кол-ва правильно вынесенных положительных оценок к неверно вынесенным положительным) как наиболее подходящий для нашей задачи. Второй график также был реализован с помощью plotly, еще было использовано несколько методов из sklearn.

\section{Описание полученных результатов}

Для метода k-ближайших соседей мы обучили модель на характеристиках, подобранных feature\_importances\_.

Нам удалось добиться хороших mse и mae (0.05 и 0.03 соответственно), указывающих на низкое отклонение между фактическими и предсказанными значениями.
Тем не менее, метрика {R^2} показала, что наша модель описывает лишь 26 \%  данных.

В методе логистической регрессии было использовано шесть показателей,про которые уже было упомянуто в Выборе данных. Модель продемонстрировала отличные результаты с точностью в 96\%, для оценки также использовались матрица путаницы и ROC кривая, на которых модель тоже показала себя хорошо. 


\end{document}